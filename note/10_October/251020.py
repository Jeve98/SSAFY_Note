"""
[251020]

<AI 라이브 강의>

거대 언어 모델 (Text Foundation Model) : 빅데이터, Self-Supervised Learning을 이용한 Attention 기반 Transformer model로써 더 큰 모델, 더 많은 데이터를 통해 창발성이 나타나기 시작한 언어 모델을 의미
ex) Chat-GPT, ...
- Scaling Law (규모의 법칙) : 더 많은 데이터와 큰 모델, 긴 학습 시간이 만들어 내는 더 좋은 성능
- Emergent Property (창발성) : 특정 규모를 넘어선 모델에서 갑자기 발현되는 성질로 in-context learning(주어진 설명, 예시만으로 새로운 테스크 수행 가능), 추론 능력 등이 있음

- 폐쇄형 : 모델의 정보를 공개하지 않은 거대 언어 모델로 일반적으로 더 우수한 성능 및 최신 기능을 가지고 있으나 사용 시마다 비용이 발생하고 모델, 출력에 대한 정보가 제한적으로 제공됨
- 개방형 : 무료로 다운로드가 가능한 모든 구조가 공개된 거대 언어 모델로 충분한 계산 자원을 요구하며 상대적으로 성능이 부실함

- 사후 학습
    - 정렬 학습 : 거대 언어 모델의 출력이 사용자의 의도와 가치를 반영할 수 있게 진행하는 사후 학습 (응답의 가능 여부 학습 포함)
        * 지시 학습 : 주어진 지시에 대해 어떤 응답이 생성되어야 하는지에 대한 학습으로 다양한 지시 기반 입력과 이에 대한 응답으로 추가 학습을 진행
            <-> SFT(Supervised Fine-Tuning) : SFT의 경우, 별도의 학습 모델을 저장할 필요가 있지만 지시 학습은 기존 모델에 대한 학습
        * 선호 학습 : 사람이 제공하는 선호도를 기반으로 보상 모델을 학습한 뒤 이를 통해 어떤 응답이 더 선호되는지에 대한 학습
            >> 해로운 응답, 할루시네이션의 발생 빈도 감소

- 추론 [inference] : 이미 학습된 지식으로부터 결과를 도출하는 것으로 학습 내용을 기반으로 적용하는 것에 가까움
    - 디코딩 알고리즘 : EOS 토큰이 등장할 때까지 순차적 추론을 통한 토큰별 자동회귀 생성
        * Greedy Decoding : 사용하기는 쉬우나 응답이 최종적으로 최선이 아닐 수 있음
        * Beam Search : 확률이 높은 beam size개의 후보를 동시에 고려하지만 리소스 사용량이 높음
        * Sampling : 제공하는 확률을 기준으로 랜덤하게 생성하는 방법으로 운이 나쁠 경우, 생성된 응답의 품질이 감소
            - with Temperature : 확률 분포를 유저가 임의로 조작할 수 있도록 하이퍼 파라미터 추가
            - Top-K : 상위 k개의 토큰들 중에서만 랜덤하게 샘플링 진행하므로 확률 분포의 모양과 상관 없이 고정된 갯수를 가져오므로 응답 품질이 감소할 수 있음
                - Top-P : 누적 확률 P에 집중하여 K를 조절

- 추론 [reasoning] : 논리적인 과정을 거쳐 새로운 사실이나 결론을 이끌어내는 것    
    - 프롬프트 엔지니어링
        ※ 프롬프트 : 지시 + 예시
        - CoT(Chain of Thought) [창발성] : 추론 과정을 예시에 포함하여 사용하는 것으로 성능을 향상시키는 방법으로 일정 크기 이상의 모델에서만 발생

- 평가 : 구축한 시스템이 실제로 잘 동작하는지 확인하는 단계
    - 테스트 데이터 : 단, 거대 언어 모델은 다양한 테스크에 대해 동시에 학습되므로 여러 테스트의 결과를 종합적으로 판단
        - Accuracy : 정답이 정해져 있는 경우에 사용
        - 사람이 임의로 작성한 정답과 비교 (단어 수준의 유사도 / 벡터 공간에서의 유사도), 출력의 품질만을 측정, 출력의 상대적 선호 평가 : 정답이 정해져 있지 않는 경우에 사용 
            ※ LLM-as-judge (G-Eval) : 인간이 제공한 평가 기준을 통해 별개의 거대 언어 모델을 이용하여 생성 텍스트를 평가하는 방법으로 특정 위치의 응답을 선호하는 위치 편향과 품질과 무관하게 길이가 긴 응답을 선호하는 길이 편향, 생성 모델과 평가 모델이 같은 경우를 선호하는 자기 선호 편향이 발생

- 응용
    - Multi-Modal Foundation Model
    - 합성 데이터 생성

-한계
    - 환각
    - 탈옥 : 학습 과정에서 기인한 근본적인 한계로 발생하는 것으로 프롬프팅 엔지니어링을 통해 거대 언어 모델의 정렬을 우회하는 방법
    - AI 텍스트 검출 : 무분별한 사용으로 인한 새로운 문제 발생
    

<실습>

Modality (모달) : 인간이 정보를 인식할 수 있는 형태     ex) Text, Image, Audio, ...
- Multi-Modality Model: 다수의 modality를 다루는 모델


Foundation Model : 다양한 목적에 맞게 파인튜닝이 가능하며 대규모 파라미터를 기반으로 방대한 범용 데이터로 학습한 모델


Diffusion : Stable-Diffusion에 사용된 알고리즘으로 원본 이미지에 노이즈를 추가하며 어디에 노이즈를 추가했는지를 예측하며 학습하고 완전한 노이즈에서 이를 점점 제거하며 복원하는 방법으로 추론(이미지 생성)을 진행
- Positive Prompt : 생성하고자 하는 이미지에 대한 입력값
- Negative Prompt : 생성될 이미지에서 제한하고자 하는 입력값
- Guidance Scale : 생성된 이미지가 프롬프트를 얼마나 강하게 따를지에 대한 값으로 그 값이 커질 수록 내용을 충실히 반영하지만 부자연스럽게 출력될 수 있음
- Num Inference Steps : 노이즈를 제거하는 단계의 수로 높을 수록 생성 이미지 품질이 높아짐
"""