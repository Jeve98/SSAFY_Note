"""
[251029]

<AI 라이브 강의>




<실습>

RAG : 문서 이해가 아닌 유사성 높은 정보를 기반으로 한 검색 도구

QA 데이터 수집 : RAG를 이용한 fine-tuning 과정에서 '질문 > 대답' 형태로의 학습 과정을 유지하기 위해 원문을 이와 같은 형태로 전처리하여 수집하는 방법
※ chat template : 모델이 사전학습 때 사용하였던 모델 고유의 데이터 포맷
"""

"""
<AI 총 정리>

[AI - Machine Learning - Deep Learning 관계]
- AI : 주어진 환경, 데이터에 대한 인지, 학습, 추론을 통해 목표를 달성하도록 예측, 행동 선택, 계획하는 시스템
- ML : AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 방법론
- DL : ML 범주 내에서 신경망 함수를 사용한 학습 방법론


[주요 기본 용어]
- Feature : 모델이 예측에 사용하는 입력 정보로써 예측/판단의 근거/단서가 됨
    - 연속형 변수 [number] : 수치가 연속적인 스펙트럼을 이루며 실수 형태로 측정되는 값으로 표준화, 정규화 등의 전처리가 이루어짐
    - 범주형 변수 [category, object] : 유한 개의 범주/등급으로 구분되는 값으로 one-hot encoding, embedding 등의 전처리가 이루어짐
- Label : 모델이 예측하려는 정답으로, 학습의 목표값
- 학습 : 데이터와 성능 척도를 바탕으로 가설공간의 후보 Feature/Label의 관계 중 최적 모델을 찾는 과정
    ※ N-Dimension Feature Based Learning : N개의 Feature를 통해 ML이 학습하는 형태
    ※ 측정 오차 (Epsilon) : 센서와 같이 데이터를 수집함에 있어, 발생할 수 있는 임의의 오차를 의미하며 (학습 과정에서의 오차와 상이) 그 평균은 0으로 가정함
- 가설 공간 : 관계를 표현할 수 있는 모든 후보 함수들의 모음으로, Feature Space와 Label Space 위에서 정의된 함수들의 집합
- 모델 : 가설 공간에 속한 특정 함수
- Overfitting : 훈련 데이터의 우연한 패턴/잡음까지 학습하여 테스트에서 성능이 나빠지는 현상
- Underfitting : 모델이 너무 단순하거나 학습이 아직 완료되지 않아, 오류가 큰 현상
- 분포 변화 : 데이터의 분포 변동으로 인해 에러가 증가하는 현상으로 과적합과 구별됨
- Modality (모달) : 인간이 정보를 인식할 수 있는 형태     ex) Text, Image, Audio, ...


[데이터]
- EDA(Exploratory Data Analysis) : 탐색적 데이터 분석 과정으로 이상치와 결측치를 확인하기 위함
    - 상관계수 : 두 변수 간의 관계를 수치로 나타낸 것으로 -1 ~ 1 사이 값을 가지며 각 값별 상관관계는 다음과 같으며 히드맵을 통해 모든 변수간의 상관계수를 확인할 수 있음
        ※ 변수간 연관이 없이 독립적이라면 계수 해석이 명확하지만 서로 연관되어 있다면 계수 추정이 불안정해지고 해석에 혼동이 발생할 수 있음

        * 1 : 완전한 양의 상관관계
        * 0.7 : 강한 양의 상관관계
        * 0 : 상관없음
        * -0.7 : 강한 음의 상관관계
        * -1 : 완전한 음의 상관관계
        ※ 관찰 데이터의 상관관계로 인과 관계를 주장할 수는 없음 (ex. 아이스크림 소비량 (x) and 상어에 물리는 사건 (y))

- 데이터 전처리
    - 표준화 : 평균을 0, 표준편차를 1로 바꾸어 모든 변수의 영향력을 동일하게 만드는 과정
    - one-hot encoding : 벡터 공간에서 1인 한 원소을 제외하고 모든 원소가 0인 벡터를 의미하며 단어를 one-hot 표현으로 바꾸는 과정을 의미
        - 차원의 저주 : 차원이 커질 수록 데이터가 점점 더 희소해져 활용이 어려움
        - 의미적 정보 부족 : 단어 간의 유사도 측정이 불가
    - Word encoding : 단어를 단어 사이의 의미적 관계를 포착할 수 있는 밀집되고 연속/분산적 벡터 표현으로 나타내는 방법으로 의미적 유사성 반영이 가능
        ex) Word2Vec : SG + CBOW
        - Skip-gram(SG) : 중심 단어를 통해 주변 단어를 예측하는 알고리즘으로 중심 단어 주변의 윈도우 크기만큼의 단어를 문맥으로 해석하며 작은 데이터에도 잘 동작하고 희귀 단어나 구 표현에 강하지만 학습이 느림
        - Continuous Bag of Words(CBOW) : 주변 단어를 통해 중심 단어를 예측하는 알고리즘으로 학습 속도가 빠르고 자주 나오는 단어에 강하지만 희귀 단어 표현에 약함

- Sequential Data : 데이터의 입력 순서와 순서를 통해 입력되는 데이터 사이의 관계가 중요한 데이터로 순서가 중요하며 장기 의존성을 띄고 가변 길이를 가짐 (ex. 오디오, 텍스트, 비디오)
    ※ 고정된 입력 길이를 가지며 장기 의존성이 떨어지는 기존의 모델로는 처리가 난해하여 Sequential Model의 필요성 대두

- 토크나이제이션 : 문장을 입력값으로 사용하기 위해 토큰 단위로 잘라 수로 변환하는 과정
    ※ 단어의 접두사/접미사 등 변형을 반영하고 추론 속도 및 메모리 효율성을 증가시키며 Out of Vocabulary를 해결하기 위한 방법
    - 토큰화가 완성되어 있는 사전을 기반으로 입력 데이터를 사전에 있는 토큰으로 구성될 수 있도록 변환
        - Word Piece : 글자 단위로 분할한 후, 함께 등장하는 빈도가 높은 글자 조합의 점수를 측정하여 이를 기반으로 토큰을 선정
            ex) BERT : Word Piece 토크나이저를 사용한 Transformer 구조의 LLM 모델
        - Byte Level BPE : Byte 단위로 분할한 후, 함께 등장하는 빈도가 높은 Byte 조합으로 토큰을 선정

- 임베딩 모델 : 단어를 의미 공간이라는 벡터 공간에 맵핑하는 모델로 이를 통해 유사 단어를 알 수 있어, 신경망의 front에 별개로 배치됨
    ※ 임베딩 모델과 본 모델의 학습은 별개로 이루어짐
    - Pooling : 다수의 벡터값을 하나로 합치는 것으로 이를 통해 각 단어에 대한 벡터를 모아 문장으로써 모델의 입력값으로 사용
    - Cos 유사도 (L2 정규화) : 벡터의 방향을 기준으로 유사도를 판별하는데 이 때 두 벡터 사이의 방향 차이를 구하기 위한 방법
        - 크기 정보도 함께 사용하는 LLM에서는 잘 사용하지 않지만, 이미지/텍스트 검색과 같이 크기 정보가 필요 없는 경우, 주로 사용


[주요 학습 방법]
- 지도 학습 : 처음 보는 데이터에서, 예측 성능 향상을 위해 feature와 label을 가지고 예측 규칙을 학습하는 방법
    - 회귀 : 숫자인 label을 예측
        ※ 결정계수 (R^2) : label의 분산 중에서 feature로 설명되는 비율로, 1이하의 값을 가지며 1에 근접할 수록 높은 설명력을 의미
        - 선형 회귀 : feature의 추세를 찾아내는 ML 모델로 데이터의 오차 합을 최소로 하는 추세를 찾음
            - Grid Search : 모든 데이터에 대한 검증을 진행하는 방법
                * MSE(Mean Squared Error) : 오차 제곱의 평균을 이용하는 것으로 큰 오류에 더 높은 가중치를 가하여 전체 오류 수준을 판단할 수 있는 손실함수
                * RMSE(Root MSE) : MSE에 제곱근을 취하여 오차를 데이터와 동일한 단위를 사용하도록 고안된 손실함수
                * MAE(Mean Absolute Error) : 오차의 절댓값의 평균을 활용하는 손실함수
            - 정규 방정식 : 역행렬을 사용
            - 경사 하강법 (Gradient Descent) : 손실함수의 값(MSE)을 y축, 파라미터를 x축으로 하는 그래프에서 최소한의 데이터만을 활용하여 미분값이 0이 되는 지점을 찾는 방법
                ※ 지역 최소점(Local Minimum), 학습률에 따른 진동 발생 가능
                ※ Non-Convex 문제 : 여러 개의 local minimum 혹은 saddle point가 존재하는 경우로 최적화가 어려움
                * Adam Optimizer : 관성과 학습률 조정을 통해 지역 최소점 문제를 회피하도록 고안된 경사 하강법
                    > 관성 : 이전의 방향과 동일한 방향으로 추가 이동
                    > 학습율 조율 : 반복 지점 발생 시, 자동으로 학습률 변동
    - 분류 : 범주인 label을 예측
        - 로지스틱 회귀 : 시그모이드 함수를 통해 두 범주 중 한 범주에 속할 확률을 예측하는 분류 기법
            - Cross Entropy : 시그모이드 함수에서 MSE를 사용할 경우, 모든 오차가 작게 변화하므로(0 <= sigmoid <= 1) 작은 오차는 작게, 큰 오차는 크게 확대해주는 손실함수를 사용
            - Accuracy : 정답율. 불균형 데이터에서는 의미가 퇴색되므로 다른 평가 요소가 함께 사용됨
            - Confusion Matrix (혼동 행렬) : 예측과 실제 값 사이의 관계를 행렬 형태로 표현한 표
                * TP_양성정답, TN_음성정답, FP_오탐, FN_누락
                * 정밀도 (Precision) [TP / (TP + FP)] : 양성으로 판정한 것 중 진짜 양성인 비율로, 잘못된 양성 판정이 치명적인 경우에 사용 (ex. 스팸 메일 구분)
                * 재현율 (Recall) [TP / (TP + FN)] : 실제 양성 중 판정을 성공한 비율로, 양성을 놓치는 것이 치명적인 경우에 사용 (ex. 암 진단)
                * F1 Score : 정밀도와 재현율의 조화 평균

- 자기 지도 학습 : label이 없는 데이터에서 자기 자신을 대상으로 label을 생성하며 학습하는 방법으로 데이터의 일부를 숨기고 이를 예측하는 방식으로 학습이 진행
    - 언어 모델 : 단어 시퀀스 전체에 확률을 부여하여 문장의 자연스러움을 측정하며 자연어를 생성하는 AI 모델
        - N-gram 언어모델 : 연속된 n개의 단어 묶음이 얼마나 자주 등장하는지 통계를 수집하고 이를 통해 다음 단어를 예측하는 통계적 기법
        - Neural Machine Translation : 인공 신경망을 이용해 기계 번역을 수행하는 방법
            - Seq2Seq : 종단 간 학습이 가능한 encoder, decoder 등 2개의 LSTM으로 이루어진 신경망 구조로 번역 뿐만 아니라, 요약, 대화, 코드 생성 등 다양한 태스크에 적용 가능한 모델
                >> 초반의 떨어지는 예측 능력을 보충하기 위해 정답 단어를 decoder 입력으로 강제로 넣어주는 teacher forcing 기법을 이용
                >> Bottleneck problem : encoder는 입력 문장 전체를 하나의 벡터로 요약하여 마지막 hidden state에 문장의 모든 의미 정보가 담기는데 이때 발생할 수 있는 정보 손실을 의미
                * greedy interface : 가장 확률이 높은 단어를 선택하는 토큰 출력 방식으로 잘못된 선택을 해도 되돌릴 수 없음
                * beam search : 매 단계마다 k개의 유망한 후보를 유지하여 완성된 문장을 리스트에 추가한 후 각 후보군의 점수를 로그 확률의 합으로 구해 최종 선택하는 토큰 출력 방식
                
                * Attention : decoder가 hidden state를 생성할 때마다 encoder의 각 hidden state와의 비교를 통해 더 적합한 단어를 생성
                    - 성능 향상 뿐만 아니라 모델의 의사결정 과정에 대한 해석 가능성을 제공하고(AI 신뢰성 향상) word alignment의 별도 학습이 필요가 없음
                * Self-Attention : RNN이 하던 정보 전달을 각 단어 간의 관계 matrix(query, key, value 벡터)와 Attention으로 대신 처리하여 장기 의존성 문제를 해결하고 병렬화를 이룸
                    - QUERY Vector : 다른 단어와의 관계를 확인하고자 하는 현재 선택된 단어
                    - KEY Vector : 선택된 단어와 다른 단어 간의 관련 정도
                    - Value Vector : 각 단어들의 실제 의미
                    - 순서 정보 부재, 비선형성 부족, 미래 참조 문제 발생
                        * 입력
                            - Positional Encoding : 위치 벡터를 단어 임베딩 값에 더해 최종 입력으로 사용하는 것으로 순서 정보 부재 해결
                            - Feed-Forward Network : Fully Connected + ReLU 층을 추가하여 비선형적인 표현으로 확장
                        * 출력
                            - Masked Self-Attention : 미래 단어에 해당하는 항목을 마스킹하여 계산을 수행할 때 반영되지 않도록 함
            - Transformer : encoder[입력 문장의 의미적 표현으로의 변환]-decoder[인코더 표현과 지금까지 생성한 단어를 입력으로 다음 단어 예측] 구조로 설계된 신경만 모델로 n개의 decoder 블록으로 이루어짐
                ※ 기존의 encoder, decoder에 사용하던 RNN을 self-attention으로 대체한 것
                * Multi-Headed Attention : 다수의 attention을 통해 다양한 관점에서 동시에 정보 파악
                * Residual Connection : 깊은 층의 학습을 위해 layer가 전체를 예측하는 것이 아닌 기존 입력과의 차이만을 학습
                * Layer Normalization

- 비지도 학습 : label 없이 데이터의 숨겨진 구조나 패턴을 찾아내는 학습 방법으로 데이터를 표준화하는 스케일링과 다수의 시도를 권장함
    - 클러스터링 : 데이터 안에서 하위 집단을 찾는 기법들의 총칭. 내부적으로는 유사하되 집단 간에는 상이하도록 분할하며 유사도/상이도의 정도는 도메인의 맥락에 따라 정의
        * K-means : 클러스터 수를 k개로 미리 정해 분할하되, 클러스터 내부 변동의 합이 최소가 되도록 분할하는 방법으로 무작위로 클러스터 위치를 초기화한 후, 각 클러스터의 중심을 계산하여 각 관측치를 가장 가까운 중심의 클러스터에 재할당하는 것을 반복
        * 계층적 군집 : 클러스터 수를 정하지 않고 쌍별 비유사도를 계산하여 유사한 것끼리 병합한 뒤, 생성된 덴드로그램을 기반으로 원하는 클러스터 수를 생성할 수 있는 높이에서 분할하는 방법
            - Single Link : 두 클러스터 내 데이터의 쌍별 거리 중, 최소값을 군집 간 거리로 고려
            - Complete Link : 두 클러스터 내 데이터의 쌍별 거리 중, 최대값을 군집 간 거리로 고려
            - Average Link : 두 클러스터 내 데이터의 쌍별 거리 중, 평균을 군집 간 거리로 고려

- 강화 학습 : 보상을 최대화하는 방법으로 진행하는 학습 방법
    - 알파고
- 전이 학습 : 이미 학습된 모델을 가져와서 새로운 문제에 적용하는 방법
    - 이미지 인식 모델


[모델 학습 요소]
- 활성화 함수 : 입력 신호의 총합을 출력 신호로 변환하는 함수로 신경망에 비선형성을 부여하여 복잡한 패턴에 대한 학습을 실시함
    - sigmoid : 입력이 매우 크거나 작으면 출력이 0 혹은 1에 고정되어 발생하는 기울기 소실 문제 및 출력 범위가 양수이기 때문에 편향된 업데이트가 발생
    - tanh : 기울기 소실 문제
    - ReLU : 영구적으로 죽은 뉴런이 발생할 수 있으며 0을 기준으로 비대칭이 발생
    - Leaky ReLU : 음수 영역의 기울기 값에 임의성이 포함되고 0을 기준으로 한 비대칭은 여전
    - ELU : 계산 복잡성 증가 및 추가적인 하이퍼 파라미터 요구

- 모델 정규화
    - L2 정규화 : 큰 가중치에 제곱으로 패널티 제공
    - L1 정규화 : 모든 가중치에 절댓값만큼 동일하게 패널티 제공 (중요하지 않은 가중치는 0으로 수렴)
    - Elastic net : L1과 L2를 모두 사용한 방식으로 둘의 비중을 조절하며 진행하여 변수가 많고 상관관계가 높을 때 효과적 
    - Dropout : 일부 뉴런을 의도적으로 끄는 방식으로 매 학습 스탭마다 다른 네트워크 구조가 샘플링되는 효과 발생

    
[Neural Network]
- Shallow Network : 입력 구간을 나눈 piecewise linear 함수를 사용하여 정답을 찾는 방법으로 사용된 유닛들의 함수의 합이 전체 함수로 작동하며 n개의 아웃풋이 존재한다면, n개의 서로 다른 piecewise linear 함수가 생성됨
  (ex - ReLU : z < 0 -> 0, z >= 0 -> z)
    ※ 보편적 근사 정리 : 히든 유닛을 충분히 많이 갖는다면 임의의 연속함수를 임의의 정밀도로 근사시킬 수 있음
    ※ 여기서 히든 유닛은 히든 레이어의 층을 의미하는 것이 아니라 한 층에 속해 있는 각 퍼셉트론을 의미함

- Deep Network : 다수의 shallow network가 합성된 형태로, 히든 레이어가 다수 적층되어 piecewise linear 함수가 다변화됨
    -> A : 3 area piecewise, B : 3 area piecewise 일때, shallow network로 구성할 경우, 6개의 area가 만들어지고 deep network로 구성할 경우, 9개의 area가 생성됨
    ※ Piecewise linear 함수의 area가 많다 == 표현력이 좋다

- 역전파(Backpropagation) : 출력 오차를 기준으로 그래프를 거꾸로 따라가며 연쇄법칙으로 각 노드의 미분값을 계산하는 절차로 학습 속도를 증가시키고 성능을 향상시킬 수 있음
※ 연쇄법칙 : 전체 합성 함수의 미분 값은 내부의 변화량 * 외부의 변화량으로 계산되므로 각 퍼셉트론의 미분값은 서로에게 영향을 끼침


[Sequence Data Model]
- RNN : 가변 길이를 입력으로 받을 수 있고 이전 시점의 정보를 담는 hidden state를 가진 아키텍처로 각 시점마다 recurrence 수식을 적용하여 hidden state를 업데이트하여 장기 기억을 구현함
    - 기울기 소실 문제 : 역전파 시 앞쪽 층의 기울기가 0에 가까워져 장기 의존성 학습이 어려워지는 현상 (과거 시점의 오차 신호에 대한 더 작은 기울기)
- LSTM : 기울기 소실 문제를 해결한 RNN 모델로 hidden state 뿐만 아니라 cell state를 추가하여 장기 정보를 별도로 저장하며 forget/input/output gate를 통해 cell state의 정보를 어떻게 사용할지 결정함


[Image Data Model]
- FCN : FCL(Fully-Connected Layer)를 적층하여 만든 모델
    ※ Fully-Connected Layer : 입력을 받아서 출력으로 변환하는 신경망의 기본 모듈로 입력 이미지를 1차원 벡터로 flattening 하여 선형 변환을 실시
- CNN : 합성곱 레이어, 풀링 레이어를 적충하여 만든 모델로 계층별로 이미지의 지역적 템플릿을 확인
    ※ 순서가 중요한 데이터 처리가 어렵고 긴 거리 의존성이 부족하며 픽셀 단위 복원이 불가 -> RNN, Attention, ViT(Vision Transformer) 사용
    - 합성곱 레이어 (Convolution Layer) : 입력 이미지를 입력의 depth와 동일한 depth를 가진 filter와 연산하여 feature map을 뽑아내는 모듈로 3차원 구조를 보존하며 연산
        - 수용 영역 : CNN이 이미지를 처리하면서 한 번에 볼 수 있는 영역의 크기로 이미지 전체 맥락을 이해하는데 사용되며 네트워크가 깊어질 수록 합성곱 레이어를 거치며 각 출력의 크기가 filter로 인해 점차 작은 크기로 압축되므로 점차 넓어짐
    - 풀링 (Pooling) : 효율적 연산 및 위치 변화의 강건성 확보를 위해 추가한 레이어로 입력값을 풀링 레이어만큼 압축시킴
        ※ 위치 변화 강건성 : 입력 내 객체 위치가 다소 변해도 동일한 출력을 제공하는 것으로 저해상도 정보에 근거하여 작업을 수행함으로써 이미지의 화소 이동을 무시함
        - Max Pooling : 정해진 커널 사이즈로 이미지를 나누어 각 영역 내 가장 큰 값을 선택하는 연산
    - 스트라이드 합성곱 : 필터를 스트라이드 값만큼 이동한 후 출력 연산하는 것으로 합성곱 레이어와 풀링 레이어를 하나의 레이어로 대체하여 이들을 함께 처리하는 효과를 내고 해상도 저하로 인한 정보 손실 역시도 줄어듬
    ex) AlexNet : 5개의 합성곱 레이어, 3개의 FCL을 이용한 CNN 모델로 딥러닝을 이용한 첫 CNN 혁명
    ex) VGGNet : 공간 해상도를 줄이는 대신 깊이를 늘려 정보를 유지한다는 룰 아래에 만들어진 CNN 모델로 작고 단순한 필터를 깊게 쌓는 것으로 성능을 향상시키고 단순한 설계를 바탕으로 모델 해석이 용이해졌으며 특징 추출기, 전이학습에 강력한 베이스라인으로 작용
    ex) ResNet : 합성곱(Convolution) 블록과 잔차(Residual) 블록을 활용한 CNN 모델로 잔차 블록을 통해 입력을 추가적으로 다음 블록으로 넘기는 연산을 진행하는 것으로 과거의 성능을 보장함
    ex) MobileNet : 공간과 채널을 2단계(깊이별/화소별)로 분리하여 처리하는 것으로 모바일/임베디드 환경에서 구동이 가능하도록 구성된 CNN 모델
- Cross-Attention : 둘 이상의 이종 데이터에서 Query/Key/Value를 정의하여 유사도를 반영하고 서로 다른 입력간 연결망을 구축
- ViT : 이미지 인식을 위해 고안된 Transformer 모델로 기존 Transformer의 인코더 부분만 사용하여 이미지를 패치로 분할한 뒤, 위치 정보를 추가하고 사용
    - 증류학습 : 상당한 양의 데이터와 연산 자원을 대체하기 위한 학습 기법으로 Teacher-Student 모델을 기반으로 정답 라벨 뿐만 아니라 유사 클래스 간의 확률 분포를 함께 학습시키는 방법
    ex) Swin Transformer : 윈도우 영역을 지정하고 그 내부의 Attention에만 집중하는 ViT의 변종 모델

    
[Foundation Model]
- Foundation Model : 다양한 작업에 폭넓게 활용될 수 있도록 대규모 데이터로 사전 학습된 범용 대형 AI 모델로 Creation > Curation > Training > Adaptation > Deployment 과정을 거침 
    ※ 새로운 모델 '학습' 패러다임에서 학습된 모델에 대한 '활용' 패러다임으로의 시프트
    - [대규모] : Transformer 모델 구조에 쉬운 데이터 수집을 기반으로 대규모 언어 데이터를 학습
        ※ Scaling Law (규모의 법칙) : 더 많은 데이터와 큰 모델, 긴 학습 시간이 만들어 내는 더 좋은 성능
        ※ Emergent Property (창발성) : 특정 규모를 넘어선 모델에서 갑자기 발현되는 성질로 in-context learning(주어진 설명, 예시만으로 새로운 테스크 수행 가능), 추론 능력 등이 있음
    - [적응성] : 높은 파인튜닝 성능
    - [범용성] : 다양한 작업과 한정되지 않는 출력 지원

    - 적응 활용 (ex. 프롬프트 엔지니어링/튜닝, 적응 학습, 파인튜닝, ...)
        - Zero-Shot : 처음 보는 문제를 추가 학습 없이 바로 적용하는 것
        - Few-Shot : 예제 일부만 제공한 뒤, 적용하는 것
        - Fine-Tuning : 모델 자체에 대한 업데이트, 최신 정보에 대한 최적화
            * PEFT(Paremeter-Efficient Fine-Tuning) : 프롬프트 튜닝, Adaptor 모듈 추가 학습
            * Partial Fine Tuning : 일부 layer의 parameter만 변화
            * Full Fine Tuning : 모델 전체의 parameter가 변화하지만 성능 향상을 위해서는 막대한 양의 데이터 요구
    
    - Text Foundation Model : 빅데이터, Self-Supervised Learning을 이용한 Attention 기반 Transformer model로써 더 큰 모델, 더 많은 데이터를 통해 창발성이 나타나기 시작한 언어 모델을 의미
        - 폐쇄형 : 모델의 정보를 공개하지 않은 거대 언어 모델로 일반적으로 더 우수한 성능 및 최신 기능을 가지고 있으나 사용 시마다 비용이 발생하고 모델, 출력에 대한 정보가 제한적으로 제공됨
        - 개방형 : 무료로 다운로드가 가능한 모든 구조가 공개된 거대 언어 모델로 충분한 계산 자원을 요구하며 상대적으로 성능이 부실함

        - 사후 학습
            - 정렬 학습 : 거대 언어 모델의 출력이 사용자의 의도와 가치를 반영할 수 있게 진행하는 사후 학습 (응답의 가능 여부 학습 포함)
                * 지시 학습 : 주어진 지시에 대해 어떤 응답이 생성되어야 하는지에 대한 학습으로 다양한 지시 기반 입력과 이에 대한 응답으로 추가 학습을 진행
                    <-> SFT(Supervised Fine-Tuning) : SFT의 경우, 별도의 학습 모델을 저장할 필요가 있지만 지시 학습은 기존 모델에 대한 학습
                * 선호 학습 : 사람이 제공하는 선호도를 기반으로 보상 모델을 학습한 뒤 이를 통해 어떤 응답이 더 선호되는지에 대한 학습
                    >> 해로운 응답, 할루시네이션의 발생 빈도 감소
        - 추론 [inference] : 이미 학습된 지식으로부터 결과를 도출하는 것으로 학습 내용을 기반으로 적용하는 것에 가까움
            - 디코딩 알고리즘 : EOS 토큰이 등장할 때까지 순차적 추론을 통한 토큰별 자동회귀 생성
                * Greedy Decoding : 사용하기는 쉬우나 응답이 최종적으로 최선이 아닐 수 있음
                * Beam Search : 확률이 높은 beam size개의 후보를 동시에 고려하지만 리소스 사용량이 높음
                * Sampling : 제공하는 확률을 기준으로 랜덤하게 생성하는 방법으로 운이 나쁠 경우, 생성된 응답의 품질이 감소
                    - with Temperature : 확률 분포를 유저가 임의로 조작할 수 있도록 하이퍼 파라미터 추가
                    - Top-K : 상위 k개의 토큰들 중에서만 랜덤하게 샘플링 진행하므로 확률 분포의 모양과 상관 없이 고정된 갯수를 가져오므로 응답 품질이 감소할 수 있음
                        - Top-P : 누적 확률 P에 집중하여 K를 조절
        - 추론 [reasoning] : 논리적인 과정을 거쳐 새로운 사실이나 결론을 이끌어내는 것    
            - 프롬프트 엔지니어링
                ※ 프롬프트 : 지시 + 예시
                - CoT(Chain of Thought) [창발성] : 추론 과정을 예시에 포함하여 사용하는 것으로 성능을 향상시키는 방법으로 일정 크기 이상의 모델에서만 발생
        - 평가 : 구축한 시스템이 실제로 잘 동작하는지 확인하는 단계
            - 테스트 데이터 : 단, 거대 언어 모델은 다양한 테스크에 대해 동시에 학습되므로 여러 테스트의 결과를 종합적으로 판단
                - Accuracy : 정답이 정해져 있는 경우에 사용
                - 사람이 임의로 작성한 정답과 비교 (단어 수준의 유사도 / 벡터 공간에서의 유사도), 출력의 품질만을 측정, 출력의 상대적 선호 평가 : 정답이 정해져 있지 않는 경우에 사용 
                    ※ LLM-as-judge (G-Eval) : 인간이 제공한 평가 기준을 통해 별개의 거대 언어 모델을 이용하여 생성 텍스트를 평가하는 방법으로 특정 위치의 응답을 선호하는 위치 편향과 품질과 무관하게 길이가 긴 응답을 선호하는 길이 편향, 생성 모델과 평가 모델이 같은 경우를 선호하는 자기 선호 편향이 발생
        - 응용
            - Multi-Modal Foundation Model
            - 합성 데이터 생성
        -한계
            - 환각
            - 탈옥 : 학습 과정에서 기인한 근본적인 한계로 발생하는 것으로 프롬프팅 엔지니어링을 통해 거대 언어 모델의 정렬을 우회하는 방법
            - AI 텍스트 검출 : 무분별한 사용으로 인한 새로운 문제 발생


[멀티모달 언어 모델]
- VLM(Vision-Language Model) : foundation Image/Text Encoder/Decoder를 별도 학습을 진행하는 Linear Projection으로 연결
    - 멀티모달 정합 (Multi-Modal Alignment) : 서로 다른 2가지 이상의 모달리티 간의 공통된 임베이딩 벡터 공간을 구성하는 것으로 이들 간의 유사도 비교가 가능
        - ImageBIND : 각종 모달리티 공간을 공유하도록 학습
    - SoM(Set of Mark) : 부족한 시각 능력을 보완하여 비약적인 성능 향상을 일으키는 트릭으로 물체 탐지, 세그멘테이션을 해줄 별도의 foundation model을 이용하여 본 이미지에 오버레이 시키는 방법 (입력의 전처리)
    
    ex) CLIP(Contrastive Language Image Pre-training) : ViT 멀티모달 Foundation Model로 언어와 이미지의 유사도를 기준으로 학습되어 있으며 오디오를 포함한 6가지 모달리티 관계 학습으로 확장 가능
        - 인터넷 데이터를 통한 대조 학습 기반의 언어/이미지를 지도 학습 기반으로(HTML-img tag's alt text) 사전 학습하여 자연어 기반 시각 개념을 학습
        ※ 대조 학습 : cos 유사도를 기반으로 목표 이미지(앵커)를 대응하는 텍스트와 가깝게, 일치하지 않는 텍스트는 멀게 위치
            >> 생성된 유사도를 손실함수로 사용하여 각 입력에 대한 역전파를 수행할 경우, 크로스 모달 모델(이미지 캡셔닝, 이미지 생성)로의 변환이 가능
    ex) SigLIP : softmax 대신 sigmoid 기반 손실함수를 사용한 모델
        >> 학습에 중요한 것은 양성인 것의 거리를 줄이는 것이지만 CLIP에서는 음성인 것과의 거리를 떨어트리는 것에 집중하는 경향이 발생하는데 이를 sigmoid 함수를 통해 영향력 제한을 걸어줌
    ex) LLaVA : 이미지 인식과 텍스트 생성을 결합하고 fine-tuning을 적용하여 시각적 질문 응답 작업에서 뛰어난 성능을 보이고 학습이 상대적으로 쉬움
    ex) Qwen-VLM : 다수의 이미지 입력 및 multi-language 지원이 가능한 모델
        - M-RoPE(Multi-Modal Rotary Position Embedding) : 1D 텍스트, 2D 시각, 3D 비디오에 대한 위치 민감 정보를 부여할 수 있는 기술
    ex) InternVL : 오픈소스 VLM
"""