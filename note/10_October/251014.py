"""
[251014]

<AI 라이브 강의>

선형회귀 : 입력 변수와 출력 변수 사이의 관계를 직선 형태로 근사하여 예측하는 통계적 방법으로 지도학습의 기초가 되는 접근법
- 단순 선형회귀 : 한 개의 설명변수와 하나의 반응변수 사이의 선형 관계를 찾는 방법
    - 최소 제곱법 : RSS(실제 관측값과 예측값의 차이를 제곱해 합한 값)를 최소화 하는 방법
        - t-statistic == Coefficient / Std.Error : 10 이상의 값을 가진다면 강한 선형성을 가진다고 할 수 있음
        - p-value : 통계적 유의성을 의미하며 0.05를 기준으로 봄
- 다중 선형회귀 : 독립 변수가 여러개 존재할 때 사용하는 회귀 분석 기법

>> 변수간 연관이 없이 독립적이라면 계수 해석이 명확하지만 서로 연관되어 있다면 계수 추정이 불안정해지고 해석에 혼동이 발생할 수 있음
>> 관찰 데이터의 상관관계로 인과 관계를 주장할 수는 없음
    ex) 아이스크림 소비량 (x) and 상어에 물리는 사건 (y)


로지스틱 회귀 : 시그모이드 함수를 활용해 0 ~ 1 범위 내 확률값을 통해 범주 분류하는 방법
- MLE(Maximum Likelihood Estimation) : 우도(likelihood) 값을 높여 최대화 되도록 하기 위한 모델 평가법으로 우도 값을 바로 계산하기에는 무리가 있기에 로그를 취한 log-likelihood 값을 이용하며 이때, log는 단조 증가 함수임으로 이를 최대화 하는 것은 우도값을 최대화 하는 것과 동일함


Neural Network
- Shallow Network : 입력 구간을 나눈 piecewise linear 함수를 사용하여 정답을 찾는 방법으로 사용된 유닛들의 함수의 합이 전체 함수로 작동하며 n개의 아웃풋이 존재한다면, n개의 서로 다른 piecewise linear 함수가 생성됨
  (ex - ReLU : z < 0 -> 0, z >= 0 -> z)
    >> 보편적 근사 정리 : 히든 유닛을 충분히 많이 갖는다면 임의의 연속함수를 임의의 정밀도로 근사시킬 수 있음
    ※ 여기서 히든 유닛은 히든 레이어의 층을 의미하는 것이 아니라 한 층에 속해 있는 각 퍼셉트론을 의미함

- Deep Network : 다수의 shallow network가 합성된 형태로, 히든 레이어가 다수 적층되어 piecewise linear 함수가 다변화됨
    -> A : 3 area piecewise, B : 3 area piecewise 일때, shallow network로 구성할 경우, 6개의 area가 만들어지고 deep network로 구성할 경우, 9개의 area가 생성됨
    ※ Piecewise linear 함수의 area가 많다 == 표현력이 좋다


Non-Convex 문제 : 여러 개의 local minimum 혹은 saddle point가 존재하는 경우로 최적화가 어려움
>> 확률적 경사 하강법을 사용하여 매 학습에 전체 데이터를 사용하지 않고 무작위 랜덤한 데이터를 활용하여 학습하는 것으로 노이즈를 감수하여 global minimum에 빠지지 않고 계산 비용 절감을 꾀할 수 있음


역전파(Backpropagation) : 출력 오차를 기준으로 그래프를 거꾸로 따라가며 연쇄법칙으로 각 노드의 미분값을 계산하는 절차로 학습 속도를 증가시키고 성능을 향상시킬 수 있음
※ 연쇄법칙 : 전체 합성 함수의 미분 값은 내부의 변화량 * 외부의 변화량으로 계산되므로 각 퍼셉트론의 미분값은 서로에게 영향을 끼침


<실습>

EDA(Exploratory Data Analysis) : 탐색적 데이터 분석 과정으로 이상치와 결측치를 확인하기 위함
- 상관계수 : 두 변수 간의 관계를 수치로 나타낸 것으로 -1 ~ 1 사이 값을 가지며 각 값별 상관관계는 다음과 같으며 히드맵을 통해 모든 변수간의 상관계수를 확인할 수 있음
    * 1 : 완전한 양의 상관관계
    * 0.7 : 강한 양의 상관관계
    * 0 : 상관없음
    * -0.7 : 강한 음의 상관관계
    * -1 : 완전한 음의 상관관계

- 분포 : 데이터가 퍼져있는 '모양'으로 각 값마다 빈도수를 통해 확인이 가능
    ※ 평균(중심 위치), 분산(평균 주변으로 퍼져있는 수준), 표준편차(퍼짐의 강도), 왜도(좌우측의 치우침), 첨도(가운데의 뾰족한 정도)


데이터 전처리
- 표준화 : 평균을 0, 표준편차를 1로 바꾸어 모든 변수의 영향력을 동일하게 만드는 과정


모델 평가
- 손실 평가
    - MSE : 오차 제곱의 평균으로 error에 대한 계산 뿐만 아니라 모델 평가에도 사용 가능
    - 결정계수(R^2) : 모델이 데이터 흐름을 잘 예측하는지 평가하는 값으로 1 이하의 값을 가짐

    ex) Logistic Regression (Confusion Metrix)
        - Accuracy : 정답율
        - F1-Score : 정밀도, 재현율의 조화평균 - 2 * 정밀도 * 재현율 / (정밀도 + 재현율)
            ※ 정밀도 : TP / (TP + FP) >> 참을 잘못 평가하면 안되는 경우
            ※ 재현율 : TP / (TP + FN) >> 참을 놓치면 안되는 경우
        - AUC(ROC-AUC) : 참과 거짓을 잘 구분하는 정도
- 신규 데이터 검증
    - Train / Validation / Test


PCA (주성분 분석) : 데이터의 차원을 줄여 주요한 패턴을 2 ~ 3 개의 축으로 표현하는 기법으로 feature의 정보를 유지하며 진행됨
※ n_components 값을 실수로 줄 경우, 해당 퍼센티지 이상의 분산이 되도록 패턴 갯수를 알아서 조절해줌


Scikit Learn : 머신러닝의 대표적인 라이브러리
TensorFlow : 딥러닝에 특화된 라이브러리
PyTorch : 딥러닝에 특화된 라이브러리로 코드 간결성이 보다 높음
"""